{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import src.globals as g\n",
    "import src.utils as utils\n",
    "\n",
    "import torch \n",
    "\n",
    "import src.data_handler as handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(g.DATA_FOLDER,'training_set.json')\n",
    "squad_dataset = handling.RawSquadDataset(dataset_path)\n",
    "\n",
    "df = squad_dataset.train_df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "df[\"context\"] = df[\"context\"].apply(lambda x: [sent.text for sent in nlp(x).sents])\n",
    "\n",
    "df = df.explode(\"context\", ignore_index=True)\n",
    "\n",
    "df = df.drop(df[[x[0] not in x[1] for x in zip(df['answer'], df['context'])]].index)\n",
    "\n",
    "df = (df.groupby(['context_id', 'question_id', 'title', 'question', 'answer', 'label_char'], sort = False).agg({'context': lambda x: \",\".join(x)}).reset_index())\n",
    "df = df[['context_id', 'question_id', 'title', 'context', 'question', 'answer', 'label_char']]\n",
    "\n",
    "df.to_csv('data/new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocab = utils.get_Glove_model_and_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import  Tokenizer, Encoding\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.normalizers import Lowercase, Strip, StripAccents, NFD, BertNormalizer\n",
    "from tokenizers.normalizers import Sequence as NormSequence\n",
    "from tokenizers.pre_tokenizers import Punctuation, Whitespace\n",
    "from tokenizers.pre_tokenizers import Sequence as PreSequence\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from datasets import Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token=g.UNK_TOKEN))\n",
    "tokenizer.normalizer = BertNormalizer(handle_chinese_chars=False) #NormSequence([NFD(), StripAccents(), Lowercase(), Strip()])    \n",
    "tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n",
    "\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[SOS] $A [EOS]\",\n",
    "    pair=\"[SOS] $A [EOS] [SOS]:1 $B:1 [EOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[SOS]\", 2),\n",
    "        (\"[EOS]\", 3),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "trainer = WordLevelTrainer(special_tokens=[g.PAD_TOKEN,g.UNK_TOKEN,g.SOS_TOKEN,g.EOS_TOKEN],vocab_size=40000)   #min_frequency\n",
    "\n",
    "#l = df.context.to_list() + df.answer.to_list()\n",
    "l = df.question.to_list()\n",
    "tokenizer.train_from_iterator(l,trainer=trainer) \n",
    "tokenizer.enable_padding(direction=\"right\", pad_id=tokenizer.token_to_id(g.PAD_TOKEN), pad_type_id=1, pad_token=g.PAD_TOKEN)\n",
    "tokenizer.get_vocab_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(batch):\n",
    "\n",
    "    question_encodings: list[Encoding] = tokenizer.encode_batch(batch['question'])\n",
    "\n",
    "    batch = {\n",
    "        'question_ids': torch.tensor([e.ids for e in question_encodings]),\n",
    "        'question_mask': torch.tensor([e.attention_mask for e in question_encodings]),\n",
    "    }\n",
    "\n",
    "    return batch\n",
    "\n",
    "hf_dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = hf_dataset[49591,49592,49593]\n",
    "\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[49592,'question']\n",
    "from src.evaluation import get_tokens\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric('bleu')\n",
    "\n",
    "\n",
    "a = tokenizer.decode_batch(ex['question_ids'].tolist())\n",
    "b = tokenizer.decode_batch(ex['question_ids'].tolist())\n",
    "\n",
    "a\n",
    "b\n",
    "c = metric.compute(predictions=[get_tokens(a[0])],references=[[get_tokens(b[1])]])\n",
    "print(c['bleu'])\n",
    "\n",
    "\n",
    "# for t,p in zip(a,b) :\n",
    "#     c = metric.compute(predictions=[get_tokens(p)],references=[[get_tokens(t)]])\n",
    "#     print(c['bleu'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.mean(torch.tensor([3.0,4,5]))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex['question_mask'].bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric('sacrebleu')\n",
    "\n",
    "metric.compute(predictions=a,references=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens([g.PAD_TOKEN,g.UNK_TOKEN]) #,g.SOS_TOKEN,g.EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = df.context.to_list() + df.answer.to_list() \n",
    "s = set()\n",
    "for e in l :\n",
    "    # if 'intellectu' in e:\n",
    "    #     print(e)\n",
    "    s.update(e.split())\n",
    "\n",
    "len(s)\n",
    "        \n",
    "\n",
    "#tokenizer.encode('To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?').tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save('data/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for e in tokenizer.get_vocab().keys() :\n",
    "    if e not in vocab:\n",
    "        # print(e)\n",
    "        n+=1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.id_to_token(1)\n",
    "tokenizer.token_to_id('plda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = df.loc[49591]\n",
    "r2 = df.loc[49593]\n",
    "s1 = r1['question']\n",
    "s2 = r2['question']\n",
    "s1\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.get_vocab()['hokkien'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as gloader\n",
    "from gensim.models import KeyedVectors\n",
    "import time \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import logging \n",
    "\n",
    "logger = logging.getLogger(g.LOG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['hello'].shape\n",
    "type(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "np.concatenate([a,[0,0,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2,3],[1,2,3],[1,2,3]],[[4,5,6],[4,5,6],[4,5,6]],[[7,8,9],[7,8,9],[7,8,9]]])\n",
    "\n",
    "b = torch.tensor([[[1,2,3,1],[1,2,3,1],[1,2,3,0]],[[4,5,6,0],[4,5,6,1],[4,5,6,0]],[[7,8,9,1],[7,8,9,1],[7,8,9,1]]])\n",
    "\n",
    "\n",
    "start = np.array([0,1,0])\n",
    "end = np.array([1,1,2])\n",
    "\n",
    "c = (start[:,None] <= np.arange(a.shape[1])).view('i1')    #np.less_equal.outer(start, np.arange(a.shape[1])).view('i1')\n",
    "d = (end[:,None] >= np.arange(a.shape[1])).view('i1')\n",
    "c\n",
    "d\n",
    "f = c*d\n",
    "\n",
    "f\n",
    "\n",
    "f = torch.from_numpy(f)\n",
    "\n",
    "f = f.unsqueeze(-1)\n",
    "\n",
    "r = torch.cat((a,f),dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_m = torch.rand((20,5))\n",
    "enc_m[0] = torch.zeros(5)\n",
    "\n",
    "enc_emb = nn.Embedding.from_pretrained(enc_m,padding_idx=0)\n",
    "\n",
    "h_dim = 3\n",
    "\n",
    "rnn = nn.LSTM(5+1, h_dim, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_ids = torch.tensor([[1,2,3,0,0,0],[3,7,8,12,17,19],[3,15,4,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_embeds = enc_emb(ctx_ids)\n",
    "\n",
    "ctx_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.tensor([0,2,3])\n",
    "end = torch.tensor([1,4,3])\n",
    "\n",
    "\n",
    "t1 = torch.le(start.unsqueeze(-1),torch.arange(ctx_embeds.shape[1])).float()\n",
    "t2 = torch.ge(end.unsqueeze(-1),torch.arange(ctx_embeds.shape[1])).float()\n",
    "\n",
    "\n",
    "m = torch.mul(t1,t2).unsqueeze(-1)\n",
    "\n",
    "r = torch.cat((ctx_embeds,m),dim=2)\n",
    "\n",
    "r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = rnn(r)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape\n",
    "v = torch.mean(out,dim=1)\n",
    "v.shape\n",
    "v = v.unsqueeze(1).expand(out.size())\n",
    "\n",
    "torch.add(v,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(out,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros((3,5,10))\n",
    "\n",
    "c = torch.rand(3,10)\n",
    "\n",
    "b.shape\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:,1,:] = c\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answ_ids = torch.tensor([[1,2,0],[8,12,17],[1,0,0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.tensor([0,2,3])\n",
    "end = torch.tensor([1,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answ_embeds = enc_emb(answ_ids)\n",
    "\n",
    "answ_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.vstack([torch.arange(s,s+answ_embeds.shape[1]) for s in start])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.arange(answ_embeds.shape[0]).reshape(answ_embeds.shape[0],1,1)\n",
    "j = index.unsqueeze(-1)\n",
    "k = torch.arange(6)                   \n",
    "\n",
    "c = out[i,j,k]\n",
    "d = torch.cat((c,answ_embeds),dim=2)\n",
    "\n",
    "l = pack_padded_sequence(d,[2,3,1],batch_first=True,enforce_sorted=False)\n",
    "\n",
    "pad_packed_sequence(l,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.tensor([0,2,3])\n",
    "end = torch.tensor([1,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(answ_embeds.shape[0],answ_embeds.shape[1],h_dim*2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(answ_embeds.shape[0]):\n",
    "    z[i,0:end[i]+1-start[i],:] = out[i,start[i]:end[i]+1,:]\n",
    "\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((z,answ_embeds),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answ_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2,3],[11,2,3],[1,2,3]],[[4,5,6],[43,5,6],[4,5,6]]])\n",
    "b = torch.tensor([[[2,3,4],[2,3,4],[2,3,4]],[[5,6,7],[5,6,7],[5,6,7]]])\n",
    "\n",
    "c = (a,b)\n",
    "\n",
    "tuple((torch.cat((hidden[0:hidden.size(0):2], hidden[1:hidden.size(0):2]), dim=2) for hidden in c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[1,2,3],[11,2,3],[1,2,3]],[[4,5,6],[43,5,6],[4,5,6]]])\n",
    "b = torch.tensor([[1,2,2],[0,1,2]])\n",
    "\n",
    "\n",
    "a.view(-1,a.shape[-1])\n",
    "b.view(-1).unsqueeze(-1)\n",
    "\n",
    "a[:,1:].contiguous().view(-1,a.shape[-1])\n",
    "b[:,1:].contiguous().view(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_raw = torch.rand((5,7,4))\n",
    "pred_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = torch.randint(1,6,(5,7))\n",
    "true\n",
    "pad_mask = torch.tensor([[1,1,1,1,1,0,0],[1,1,1,1,0,0,0],[1,1,1,1,1,1,0],[1,1,1,1,1,1,1],[1,1,1,0,0,0,0]])\n",
    "pad_mask\n",
    "\n",
    "torch.where(pad_mask!=0,true,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "pred_logits = F.log_softmax(pred_raw,dim=2)\n",
    "pred = pred_logits.argmax(dim=2)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.eq(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pred.eq(true).masked_select(pad_mask.bool()).float().mean().item()\n",
    "\n",
    "a\n",
    "# b = a.sum().item()\n",
    "# c = a.size(0)\n",
    "\n",
    "# b/c\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d27d3bb0e70e29a6993d11ced729f39970904d8c590c3a159e115fe96c0c042"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('squad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
