{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berse\\miniconda3\\envs\\squad\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import src.utils as utils \n",
    "import src.globals as globals\n",
    "import src.data_handler as handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(globals.DATA_FOLDER,'training_set.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocab = utils.load_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dataset = handling.RawSquadDataset(dataset_path)\n",
    "\n",
    "df = squad_dataset.train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57912</th>\n",
       "      <td>12472</td>\n",
       "      <td>5727b1c13acd2414000de9eb</td>\n",
       "      <td>Hindu_philosophy</td>\n",
       "      <td>Advaita literally means \"not two, sole, unity\"...</td>\n",
       "      <td>What means</td>\n",
       "      <td>Advaita</td>\n",
       "      <td>(0, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       context_id               question_id             title  \\\n",
       "57912       12472  5727b1c13acd2414000de9eb  Hindu_philosophy   \n",
       "\n",
       "                                                 context     question  \\\n",
       "57912  Advaita literally means \"not two, sole, unity\"...  What means    \n",
       "\n",
       "        answer label_char  \n",
       "57912  Advaita     (0, 7)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['question_id']=='5727b1c13acd2414000de9eb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ids = open(os.path.join(globals.DATA_FOLDER,'error_ids.txt')).read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['question_id'].isin(error_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [context_id, question_id, title, context, question, answer, label_char]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['question_id']=='56cf1a05aab44d1400b88d7f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = np.array(list(map(lambda x: x[0],df['label_char'])))\n",
    "ends = np.array(list(map(lambda x: x[1],df['label_char'])))\n",
    "\n",
    "s = starts - ends\n",
    "\n",
    "df[s==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import  Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.normalizers import Lowercase, Sequence, Strip, StripAccents\n",
    "from tokenizers.pre_tokenizers import Punctuation\n",
    "from tokenizers.pre_tokenizers import Sequence as PreSequence\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from datasets import Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf_dataset = Dataset.from_pandas(squad_dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(vocab,unk_token=globals.UNK_TOKEN))\n",
    "tokenizer.normalizer = Sequence([StripAccents(), Lowercase(), Strip()])\n",
    "tokenizer.pre_tokenizer = PreSequence([Whitespace(), Punctuation()])\n",
    "tokenizer.enable_padding(direction=\"right\", pad_id=vocab[globals.PAD_TOKEN], pad_type_id=1, pad_token=globals.PAD_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Encoding\n",
    "\n",
    "def transform(batch):\n",
    "\n",
    "    context_encodings: list[Encoding] = tokenizer.encode_batch(batch['context'])\n",
    "    question_encodings: list[Encoding] = tokenizer.encode_batch(batch['question'])\n",
    "    answer_encodings: list[Encoding] = tokenizer.encode_batch(batch['answer'])\n",
    "\n",
    "    starts = list(map(lambda x: x[0],batch['label_char']))\n",
    "    ends = list(map(lambda x: x[1],batch['label_char']))\n",
    "\n",
    "    encodings = {\n",
    "        #'context_ids': [e.ids for e in context_encodings],\n",
    "        # 'question_ids': [e.ids for e in question_encodings],\n",
    "        # 'context_mask': torch.tensor([e.attention_mask for e in context_encodings]),\n",
    "        # 'question_mask': [e.attention_mask for e in question_encodings],\n",
    "        'offsets': [e.offsets for e in context_encodings], \n",
    "        'context_text': batch['context'],\n",
    "        'question_text': batch['question'],\n",
    "        'answer_text': batch['answer'],\n",
    "        'context_tokens': [e.tokens for e in context_encodings], \n",
    "        'label_token_start': [e.char_to_token(starts[i]) for i,e in enumerate(context_encodings)],\n",
    "        'label_token_end': [e.char_to_token(ends[i]-1) for i,e in enumerate(context_encodings)],\n",
    "        'label_char_start': starts,\n",
    "        'label_char_end': ends,\n",
    "        'answer_tokens': [e.tokens for e in answer_encodings], \n",
    "    }\n",
    "\n",
    "    return encodings\n",
    "\n",
    "hf_dataset.set_transform(transform,output_all_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hf_dataset[57912])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = hf_dataset[57912]\n",
    "start_token = ex['label_token_start']\n",
    "end_token = ex['label_token_end']\n",
    "start_char = ex['offsets'][start_token][0]\n",
    "end_char = ex['offsets'][end_token][1]\n",
    "\n",
    "print(start_char)\n",
    "print(end_char)\n",
    "\n",
    "ex['context_text'][start_char:end_char]\n",
    "ex['context_text'][ex['label_char_start']:ex['label_char_end']]\n",
    "ex['answer_text']\n",
    "\n",
    "len(ex['context_ids']) == len(ex['context_tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_c = ex['label_char_start']\n",
    "end_c = ex['label_char_end']\n",
    "\n",
    "starts, ends = zip(*ex['offsets'])\n",
    "\n",
    "try :\n",
    "    start_idx = starts.index(start_c)\n",
    "except :\n",
    "    print('errore start')\n",
    "\n",
    "try: \n",
    "    end_idx = ends.index(end_c)\n",
    "except :\n",
    "    print('errore end')\n",
    "\n",
    "\n",
    "ex['context_tokens'][start_idx] == ex['answer_tokens'][0]\n",
    "ex['context_tokens'][end_idx] == ex['answer_tokens'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
    "        [-0.7401, -0.8805, -0.3402, -1.1936],\n",
    "        [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
    "        [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
    "\n",
    "torch.argmax(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, OrderedDict, defaultdict\n",
    "d =  OrderedDict({'a':torch.tensor([1,0,1,1]), 'b':['ab c','Dfg H','hil','mnohgh'], 'c': [5,6,7,8], 'offsets': torch.tensor([[[0,0],[0,0]],[[1,1],[1,1]],[[2,2],[2,2]],[[3,3],[3,3]]])})\n",
    "\n",
    "# for i,e in enumerate(zip(*d.values())):\n",
    "#     print(i,e)\n",
    "#     # print(e[1])\n",
    "\n",
    "Record = namedtuple('Record', d.keys())\n",
    "b = [Record(*t) for t in zip(*(d.values()))]\n",
    "\n",
    "\n",
    "for ex in b:\n",
    "    print(ex.b[ex.offsets[ex.a][0]:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6],dtype=torch.float)\n",
    "b = torch.tensor([1,4,7,4,5,8],dtype=torch.float)\n",
    "\n",
    "np.mean(torch.abs(a-b).numpy())\n",
    "torch.abs(a-b).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'a':1 , 'b':2 , 'c':3 , 'd':4}\n",
    "d2 = {'a':1 , 'b':2 , 'c':3 , 'd':4}\n",
    "\n",
    "m = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for k,v in d2.items():\n",
    "    m[k].append(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d27d3bb0e70e29a6993d11ced729f39970904d8c590c3a159e115fe96c0c042"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('squad': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
